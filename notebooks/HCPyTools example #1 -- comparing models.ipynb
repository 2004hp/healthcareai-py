{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This package helps one compare and deploy models in two steps: 1) compare models built on most of your data (we have to hold some rows out for checking the accuracy) and 2) pick the best approach, build this model using all of your data, save the model, and deploy predictions on test data to SQL Server."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To begin step #1, we make a connection and load in data from SQL Server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from hcpytools.develop_supervised_model import DevelopSupervisedModel\n",
    "from hcpytools.deploy_supervised_model import DeploySupervisedModel\n",
    "import pandas as pd\n",
    "import pyodbc\n",
    "import random\n",
    "\n",
    "cnxn = pyodbc.connect(SERVER='localhost',\n",
    "                      DRIVER='{SQL Server Native Client 11.0}',\n",
    "                      Trusted_Connection='yes')\n",
    "\n",
    "df = pd.read_sql(\"\"\"SELECT\n",
    "                      [OrganizationLevel]\n",
    "                      ,[MaritalStatus]\n",
    "                      ,[Gender]\n",
    "                      --Predicted col has to be Y/N\n",
    "                      ,IIF([SalariedFlag]=1,'Y','N') as SalariedFlag \n",
    "                      ,[VacationHours]\n",
    "                      ,[SickLeaveHours]\n",
    "                    FROM [AdventureWorks2012].[HumanResources].[Employee]\"\"\",\n",
    "                 cnxn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see the we've loaded in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   OrganizationLevel MaritalStatus Gender SalariedFlag  VacationHours  \\\n",
      "0                  0             S      M            Y             99   \n",
      "1                  1             S      F            Y              1   \n",
      "2                  2             M      M            Y              2   \n",
      "3                  3             S      M            N             48   \n",
      "4                  3             M      F            Y              5   \n",
      "\n",
      "   SickLeaveHours  \n",
      "0              69  \n",
      "1              20  \n",
      "2              21  \n",
      "3              80  \n",
      "4              22  \n"
     ]
    }
   ],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK that looks good. What about column types?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrganizationLevel     int64\n",
      "MaritalStatus        object\n",
      "Gender               object\n",
      "SalariedFlag         object\n",
      "VacationHours         int64\n",
      "SickLeaveHours        int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks pretty good, but let's say we had to change an int to a factor column (which might happen if the factor column is 0,1,2, etc). Also, we'll change an object (factor) col to a float. This is how:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['Gender'] = df['Gender'].astype(object) # changing to factor\n",
    "df['VacationHours'] = df['VacationHours'].astype(float) # to float"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do proprocessing and split data into train/test, and store result in object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "random.seed(43) # <-- used to make results reproducible\n",
    "o = DevelopSupervisedModel(modeltype='classification',\n",
    "                           df=df,\n",
    "                           predictedcol='SalariedFlag',\n",
    "                           graincol='',#OPTIONAL/ENCOURAGED\n",
    "                           impute=True,\n",
    "                           debug=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've arranged the data and done imputation, let's create a logistic model and see how accurate it is. Note that the method is called linear, but it's classification when that argument is set above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " LogisticRegressionCV(Cs=10, class_weight=None, cv=5, dual=False,\n",
      "           fit_intercept=True, intercept_scaling=1.0, max_iter=100,\n",
      "           multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
      "           refit=True, scoring=None, solver='lbfgs', tol=0.0001, verbose=0)\n",
      "Best hyper-parameters found after tuning:\n",
      "No hyper-parameter tuning was done.\n",
      "\n",
      "AUC Score: 0.858630952381 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "o.linear(cores=1,\n",
    "         debug=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting, so an AUC above 0.8 is fairly predictive, so the linear model did fairly well. (You'll note the cell above also specifies model details.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While we've already done well, let's see how well a random forest does:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=200, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "Best hyper-parameters found after tuning:\n",
      "No hyper-parameter tuning was done.\n",
      "\n",
      "AUC Score: 0.902529761905 \n",
      "\n",
      "Variable importance:\n",
      "1. OrganizationLevel (0.488065)\n",
      "2. VacationHours (0.239089)\n",
      "3. SickLeaveHours (0.210164)\n",
      "4. Gender.M (0.032773)\n",
      "5. MaritalStatus.S (0.029909)\n"
     ]
    }
   ],
   "source": [
    "o.randomforest(cores=1,\n",
    "               debug=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oh, so that's interesting--random forest does even better with an AUC of 0.91. This means we'll choose to use the random forest model for nightly predictions. Random forest also gives us some guidance as to which variables are most important. If you have features that contribute below 0.1 in the variable importance list, you can safely leave them out of the deploy step (see the next example)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reach out to Levi Thatcher (levi.thatcher@healthcatalyst.com) if you have any questions!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
